{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\sarah\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\sarah\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from opencv-python) (1.23.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.1\n",
      "[notice] To update, run: C:\\Users\\sarah\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-pose.pt to 'yolov8n-pose.pt'...\n",
      "100%|██████████| 6.51M/6.51M [00:01<00:00, 6.71MB/s]\n",
      "Ultralytics YOLOv8.0.201  Python-3.10.11 torch-2.1.0+cpu CPU (Intel Core(TM) i5-1035G1 1.00GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=pose, mode=train, model=yolov8n-pose.pt, data=coco8-pose.yaml, epochs=100, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\pose\\train\n",
      "\n",
      "Dataset 'coco8-pose.yaml' images not found , missing path 'C:\\Users\\sarah\\Documents\\Master\\Hochschule Augsburg\\WiSe 2023\\Master Projekt KI-basierte Erkennung von Bewegungsablufen\\Code\\KI-basierte-Erkennung-von-Bewegungen\\KI-basierte-Erkennung-von-Bewegungen\\datasets\\coco8-pose\\images\\val'\n",
      "Downloading https://ultralytics.com/assets/coco8-pose.zip to 'C:\\Users\\sarah\\Documents\\Master\\Hochschule Augsburg\\WiSe 2023\\Master Projekt KI-basierte Erkennung von Bewegungsablufen\\Code\\KI-basierte-Erkennung-von-Bewegungen\\KI-basierte-Erkennung-von-Bewegungen\\datasets\\coco8-pose.zip'...\n",
      " Download failure, retrying 1/3 https://ultralytics.com/assets/coco8-pose.zip...\n",
      "Unzipping C:\\Users\\sarah\\Documents\\Master\\Hochschule Augsburg\\WiSe 2023\\Master Projekt KI-basierte Erkennung von Bewegungsabläufen\\Code\\KI-basierte-Erkennung-von-Bewegungen\\KI-basierte-Erkennung-von-Bewegungen\\datasets\\coco8-pose.zip to C:\\Users\\sarah\\Documents\\Master\\Hochschule Augsburg\\WiSe 2023\\Master Projekt KI-basierte Erkennung von Bewegungsabläufen\\Code\\KI-basierte-Erkennung-von-Bewegungen\\KI-basierte-Erkennung-von-Bewegungen\\datasets\\coco8-pose...: 100%|██████████| 27/27 [00:00<00:00, 1124.97file/s]\n",
      "Dataset download success  (3.6s), saved to \u001b[1mC:\\Users\\sarah\\Documents\\Master\\Hochschule Augsburg\\WiSe 2023\\Master Projekt KI-basierte Erkennung von Bewegungsablufen\\Code\\KI-basierte-Erkennung-von-Bewegungen\\KI-basierte-Erkennung-von-Bewegungen\\datasets\u001b[0m\n",
      "\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\sarah\\AppData\\Roaming\\Ultralytics\\Arial.ttf'...\n",
      "100%|██████████| 755k/755k [00:00<00:00, 6.67MB/s]\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1035934  ultralytics.nn.modules.head.Pose             [1, [17, 3], [64, 128, 256]]  \n",
      "YOLOv8n-pose summary: 250 layers, 3295470 parameters, 3295454 gradients, 9.3 GFLOPs\n",
      "\n",
      "Transferred 397/397 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\sarah\\Documents\\Master\\Hochschule Augsburg\\WiSe 2023\\Master Projekt KI-basierte Erkennung von Bewegungsabläufen\\Code\\KI-basierte-Erkennung-von-Bewegungen\\KI-basierte-Erkennung-von-Bewegungen\\datasets\\coco8-pose\\labels\\train... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<00:00, 70.18it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\sarah\\Documents\\Master\\Hochschule Augsburg\\WiSe 2023\\Master Projekt KI-basierte Erkennung von Bewegungsablufen\\Code\\KI-basierte-Erkennung-von-Bewegungen\\KI-basierte-Erkennung-von-Bewegungen\\datasets\\coco8-pose\\labels\\train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sarah\\Documents\\Master\\Hochschule Augsburg\\WiSe 2023\\Master Projekt KI-basierte Erkennung von Bewegungsabläufen\\Code\\KI-basierte-Erkennung-von-Bewegungen\\KI-basierte-Erkennung-von-Bewegungen\\datasets\\coco8-pose\\labels\\val... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<00:00, 210.53it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\sarah\\Documents\\Master\\Hochschule Augsburg\\WiSe 2023\\Master Projekt KI-basierte Erkennung von Bewegungsablufen\\Code\\KI-basierte-Erkennung-von-Bewegungen\\KI-basierte-Erkennung-von-Bewegungen\\datasets\\coco8-pose\\labels\\val.cache\n",
      "Plotting labels to runs\\pose\\train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 63 weight(decay=0.0), 73 weight(decay=0.0005), 72 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\pose\\train\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/100         0G      1.138      2.331     0.2073     0.9262      1.396         11        640: 100%|██████████| 1/1 [00:02<00:00,  2.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n",
      "                   all          4         14      0.927      0.905      0.907      0.668      0.845        0.5      0.535      0.352\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/100         0G      1.758      4.956     0.4311       2.31      1.658          7        640: 100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n",
      "                   all          4         14      0.888      0.857      0.902      0.665      0.843        0.5      0.535      0.348\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      3/100         0G     0.9684      2.989     0.3648     0.7099      1.122         14        640: 100%|██████████| 1/1 [00:01<00:00,  1.88s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "                   all          4         14      0.836      0.929      0.897      0.671      0.842        0.5      0.535      0.334\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      4/100         0G     0.9165      2.069      0.261      0.667      1.085         17        640: 100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n",
      "                   all          4         14      0.809      0.929      0.884      0.673      0.844        0.5      0.526       0.32\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      5/100         0G      1.164      2.332     0.3549     0.8914      1.265         16        640: 100%|██████████| 1/1 [00:01<00:00,  1.87s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n",
      "                   all          4         14      0.857      0.855      0.914      0.693      0.796      0.557      0.576      0.309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      6/100         0G      1.036      2.724     0.2951     0.5587       1.28         14        640: 100%|██████████| 1/1 [00:01<00:00,  1.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "                   all          4         14      0.762      0.917      0.895      0.667      0.767      0.571       0.57      0.293\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      7/100         0G      1.381      3.352     0.4234     0.9867      1.345         19        640: 100%|██████████| 1/1 [00:02<00:00,  2.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "                   all          4         14      0.717      0.905      0.872      0.656      0.722      0.571      0.568      0.257\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      8/100         0G        1.6      3.462     0.4018      1.352      1.315         12        640: 100%|██████████| 1/1 [00:02<00:00,  2.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "                   all          4         14       0.89      0.714      0.885      0.616      0.575      0.429      0.398      0.228\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      9/100         0G       1.37      3.561      0.383      1.146      1.328         12        640: 100%|██████████| 1/1 [00:02<00:00,  2.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                   all          4         14      0.895      0.714      0.863      0.578       0.59      0.429      0.363      0.228\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     10/100         0G     0.8129      2.676     0.3309     0.7091      1.085         16        640: 100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "                   all          4         14      0.794      0.714      0.854      0.587      0.589      0.429      0.364       0.22\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     11/100         0G      1.116       2.02     0.3591      0.663      1.133         21        640: 100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "                   all          4         14      0.885      0.643      0.785      0.556      0.587      0.429      0.413       0.23\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     12/100         0G      0.872      2.674     0.3852     0.7556       1.03         21        640: 100%|██████████| 1/1 [00:02<00:00,  2.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                   all          4         14      0.863      0.643      0.828      0.551      0.575      0.429      0.435      0.231\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     13/100         0G      0.961      1.956     0.2962     0.5376      1.014         21        640: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "                   all          4         14      0.941      0.643       0.83      0.491      0.683      0.429      0.425      0.218\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     14/100         0G      0.943       1.49     0.2784     0.5865      1.192         12        640: 100%|██████████| 1/1 [00:02<00:00,  2.09s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                   all          4         14      0.818      0.643      0.814      0.464      0.785      0.429      0.406      0.203\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     15/100         0G     0.9216      1.706     0.3114     0.5916      1.008         17        640: 100%|██████████| 1/1 [00:02<00:00,  2.21s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "                   all          4         14          1      0.629      0.785       0.45      0.665      0.357      0.326      0.182\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     16/100         0G     0.9154      1.898     0.3279     0.6148      1.104         12        640: 100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "                   all          4         14      0.869      0.643      0.741      0.415       0.58      0.357      0.315      0.179\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     17/100         0G     0.9214      2.647     0.2733     0.7437      1.162         13        640: 100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "                   all          4         14      0.727      0.571      0.643      0.396      0.553      0.357      0.309      0.168\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     18/100         0G     0.9959      4.041     0.2894     0.9309      1.108         10        640: 100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "                   all          4         14      0.727      0.571      0.643      0.396      0.553      0.357      0.309      0.168\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     19/100         0G      1.378      4.758     0.2679     0.9146       1.55          8        640: 100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "                   all          4         14      0.859      0.571      0.695      0.387      0.537      0.357      0.283      0.183\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     20/100         0G      0.777      3.022     0.3044     0.6338     0.9763         19        640: 100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                   all          4         14      0.859      0.571      0.695      0.387      0.537      0.357      0.283      0.183\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     21/100         0G     0.7642      1.087     0.2631     0.7062      1.215          7        640: 100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all          4         14      0.863      0.571      0.691       0.42       0.55      0.357      0.316      0.156\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     22/100         0G     0.8735      2.081     0.3314     0.7532       1.11         14        640: 100%|██████████| 1/1 [00:02<00:00,  2.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "                   all          4         14      0.863      0.571      0.691       0.42       0.55      0.357      0.316      0.156\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     23/100         0G     0.7835      2.483     0.3143     0.6892     0.9396         17        640: 100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "                   all          4         14      0.756        0.5      0.616      0.383      0.652      0.357      0.324      0.174\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     24/100         0G     0.6073      2.092     0.2458     0.6651     0.9914          7        640: 100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "                   all          4         14      0.756        0.5      0.616      0.383      0.652      0.357      0.324      0.174\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     25/100         0G      1.123      3.007     0.2197     0.8233      1.217          9        640: 100%|██████████| 1/1 [00:02<00:00,  2.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "                   all          4         14      0.688        0.5      0.614      0.375      0.591      0.357      0.269      0.145\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     26/100         0G       1.17       3.49     0.3686     0.9226      1.192         21        640: 100%|██████████| 1/1 [00:02<00:00,  2.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "                   all          4         14      0.688        0.5      0.614      0.375      0.591      0.357      0.269      0.145\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     27/100         0G     0.9705      3.195     0.4764     0.6151       1.02         16        640: 100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "                   all          4         14      0.684        0.5      0.575      0.353       0.67      0.357      0.265      0.108\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     28/100         0G     0.9555      2.477     0.3108     0.6925      1.064         14        640: 100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "                   all          4         14      0.684        0.5      0.575      0.353       0.67      0.357      0.265      0.108\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     29/100         0G      1.026      3.474     0.3994     0.6726      1.114         17        640: 100%|██████████| 1/1 [00:02<00:00,  2.22s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                   all          4         14      0.686        0.5      0.554      0.354      0.695      0.357      0.316      0.085\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     30/100         0G     0.9934      2.517      0.254     0.7247       1.04         13        640: 100%|██████████| 1/1 [00:02<00:00,  2.09s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "                   all          4         14      0.686        0.5      0.554      0.354      0.695      0.357      0.316      0.085\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     31/100         0G      1.391      3.284     0.3206      1.003      1.208         15        640: 100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "                   all          4         14      0.871      0.485      0.585       0.34      0.782      0.357       0.32     0.0773\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     32/100         0G      1.042       3.26      0.356     0.7786      1.107         22        640: 100%|██████████| 1/1 [00:02<00:00,  2.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "                   all          4         14      0.871      0.485      0.585       0.34      0.782      0.357       0.32     0.0773\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     33/100         0G     0.7941       2.63     0.3022     0.7036      1.089          9        640: 100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "                   all          4         14      0.674        0.5      0.551      0.288       0.35      0.143      0.119     0.0692\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     34/100         0G     0.9454      3.176     0.4066     0.9844      1.116         11        640: 100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                   all          4         14      0.674        0.5      0.551      0.288       0.35      0.143      0.119     0.0692\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     35/100         0G      1.178       2.81     0.1875      1.116      1.307         15        640: 100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "                   all          4         14      0.831      0.357      0.513      0.291      0.408      0.143      0.129     0.0622\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     36/100         0G      1.066      3.483     0.4235     0.9501      1.261         17        640: 100%|██████████| 1/1 [00:02<00:00,  2.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "                   all          4         14      0.831      0.357      0.513      0.291      0.408      0.143      0.129     0.0622\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     37/100         0G     0.9235      3.355     0.4254       0.79      1.112         19        640: 100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "                   all          4         14      0.597      0.357      0.424      0.238      0.339      0.143      0.121     0.0472\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     38/100         0G     0.9758      3.059     0.4516      1.172      1.038         16        640: 100%|██████████| 1/1 [00:02<00:00,  2.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "                   all          4         14      0.597      0.357      0.424      0.238      0.339      0.143      0.121     0.0472\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     39/100         0G     0.8213      2.704     0.3952     0.9672      1.103         12        640: 100%|██████████| 1/1 [00:02<00:00,  2.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "                   all          4         14      0.454      0.357      0.323      0.174      0.269      0.143     0.0723     0.0227\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     40/100         0G      1.205      2.666     0.3442     0.9198      1.245         12        640: 100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "                   all          4         14      0.454      0.357      0.323      0.174      0.269      0.143     0.0723     0.0227\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     41/100         0G      1.076      3.108     0.4075     0.9063      1.192         12        640: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                   all          4         14      0.537        0.5      0.453      0.244      0.378      0.143     0.0795     0.0238\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     42/100         0G     0.7337        1.9     0.3243     0.6921      1.061         14        640: 100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                   all          4         14      0.537        0.5      0.453      0.244      0.378      0.143     0.0795     0.0238\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     43/100         0G     0.9718      3.942     0.3682      0.895      1.085         14        640: 100%|██████████| 1/1 [00:02<00:00,  2.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "                   all          4         14       0.82      0.571      0.636      0.291      0.254      0.143     0.0658     0.0192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     44/100         0G      1.137      3.589     0.4217     0.8523      1.151         22        640: 100%|██████████| 1/1 [00:02<00:00,  2.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "                   all          4         14       0.82      0.571      0.636      0.291      0.254      0.143     0.0658     0.0192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     45/100         0G     0.8476      2.714      0.355     0.7916      1.085         13        640: 100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all          4         14      0.857      0.571      0.686      0.309      0.494      0.214      0.202     0.0638\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     46/100         0G     0.8036      2.929     0.3071     0.7971      1.032         12        640: 100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "                   all          4         14      0.857      0.571      0.686      0.309      0.494      0.214      0.202     0.0638\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     47/100         0G      1.096      3.866     0.3031     0.8912      1.179         15        640: 100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "                   all          4         14      0.796      0.557      0.664      0.307      0.702      0.214      0.212     0.0469\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     48/100         0G      1.123      2.615     0.3173      1.042      1.218         12        640: 100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "                   all          4         14      0.796      0.557      0.664      0.307      0.702      0.214      0.212     0.0469\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     49/100         0G      0.805      2.904     0.3528     0.6576     0.9907         16        640: 100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "                   all          4         14      0.662       0.56      0.579      0.269      0.581      0.214      0.211     0.0776\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     50/100         0G     0.8241      5.316     0.2565     0.8389      1.078         13        640: 100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "                   all          4         14      0.662       0.56      0.579      0.269      0.581      0.214      0.211     0.0776\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     51/100         0G      1.054      3.335     0.3829     0.9405      1.058         19        640: 100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                   all          4         14      0.699      0.498      0.576      0.303      0.672      0.214      0.212     0.0836\n",
      "Stopping training early as no improvement observed in last 50 epochs. Best results observed at epoch 1, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=50) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "51 epochs completed in 0.048 hours.\n",
      "Optimizer stripped from runs\\pose\\train\\weights\\last.pt, 6.8MB\n",
      "Optimizer stripped from runs\\pose\\train\\weights\\best.pt, 6.8MB\n",
      "\n",
      "Validating runs\\pose\\train\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.201  Python-3.10.11 torch-2.1.0+cpu CPU (Intel Core(TM) i5-1035G1 1.00GHz)\n",
      "YOLOv8n-pose summary (fused): 187 layers, 3289964 parameters, 0 gradients, 9.2 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "                   all          4         14      0.927      0.906      0.907      0.668      0.845        0.5      0.535      0.352\n",
      "Speed: 2.0ms preprocess, 159.0ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\pose\\train\u001b[0m\n",
      "Ultralytics YOLOv8.0.201  Python-3.10.11 torch-2.1.0+cpu CPU (Intel Core(TM) i5-1035G1 1.00GHz)\n",
      "YOLOv8n-pose summary (fused): 187 layers, 3289964 parameters, 0 gradients, 9.2 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sarah\\Documents\\Master\\Hochschule Augsburg\\WiSe 2023\\Master Projekt KI-basierte Erkennung von Bewegungsabläufen\\Code\\KI-basierte-Erkennung-von-Bewegungen\\KI-basierte-Erkennung-von-Bewegungen\\datasets\\coco8-pose\\labels\\val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                   all          4         14      0.927      0.906      0.907      0.668      0.845        0.5      0.535      0.352\n",
      "Speed: 2.3ms preprocess, 146.5ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\pose\\train2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8n-pose.pt')  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data='coco8-pose.yaml', epochs=100, imgsz=640)\n",
    "metrics = model.val()  # evaluate model performance on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 5 persons, 1: 640x640 1 person, 323.0ms\n",
      "Speed: 5.5ms preprocess, 161.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "results = model([\"images\\Women_soccer.jpg\", \"images\\woman_fitness.jpg\"])  # return a list of Results objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n"
     ]
    }
   ],
   "source": [
    "for result in results[0]:\n",
    "    boxes = result.boxes  # Boxes object for bbox outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    class_names = result.names[int(boxes.cls[0])]\n",
    "    print(class_names)\n",
    "    result.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results\n",
    "for r in results[0]:\n",
    "    im_array = r.plot()  # plot a BGR numpy array of predictions\n",
    "    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "    im.show()  # show image\n",
    "    im.save('results.jpg')  # save image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 173.0ms\n",
      "Speed: 4.0ms preprocess, 173.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 121.0ms\n",
      "Speed: 3.0ms preprocess, 121.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 114.0ms\n",
      "Speed: 2.0ms preprocess, 114.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 117.0ms\n",
      "Speed: 4.0ms preprocess, 117.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 108.0ms\n",
      "Speed: 4.0ms preprocess, 108.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 110.0ms\n",
      "Speed: 3.0ms preprocess, 110.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 107.0ms\n",
      "Speed: 2.0ms preprocess, 107.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 107.0ms\n",
      "Speed: 4.0ms preprocess, 107.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 106.1ms\n",
      "Speed: 4.0ms preprocess, 106.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 109.1ms\n",
      "Speed: 4.0ms preprocess, 109.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 98.9ms\n",
      "Speed: 3.1ms preprocess, 98.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 106.0ms\n",
      "Speed: 4.0ms preprocess, 106.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 105.9ms\n",
      "Speed: 2.0ms preprocess, 105.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 104.0ms\n",
      "Speed: 3.1ms preprocess, 104.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 109.0ms\n",
      "Speed: 2.0ms preprocess, 109.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 106.0ms\n",
      "Speed: 4.0ms preprocess, 106.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 107.9ms\n",
      "Speed: 3.1ms preprocess, 107.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 102.0ms\n",
      "Speed: 3.0ms preprocess, 102.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 107.0ms\n",
      "Speed: 2.0ms preprocess, 107.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 100.0ms\n",
      "Speed: 3.1ms preprocess, 100.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 107.0ms\n",
      "Speed: 2.0ms preprocess, 107.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 103.0ms\n",
      "Speed: 4.0ms preprocess, 103.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 103.9ms\n",
      "Speed: 4.1ms preprocess, 103.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 102.0ms\n",
      "Speed: 4.0ms preprocess, 102.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 100.0ms\n",
      "Speed: 4.0ms preprocess, 100.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 109.0ms\n",
      "Speed: 2.0ms preprocess, 109.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 103.1ms\n",
      "Speed: 3.0ms preprocess, 103.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 102.0ms\n",
      "Speed: 3.1ms preprocess, 102.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 100.0ms\n",
      "Speed: 3.0ms preprocess, 100.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 104.0ms\n",
      "Speed: 2.0ms preprocess, 104.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 103.1ms\n",
      "Speed: 3.0ms preprocess, 103.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 97.1ms\n",
      "Speed: 3.0ms preprocess, 97.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 107.0ms\n",
      "Speed: 2.0ms preprocess, 107.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 109.9ms\n",
      "Speed: 3.1ms preprocess, 109.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 104.0ms\n",
      "Speed: 3.0ms preprocess, 104.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 102.0ms\n",
      "Speed: 2.0ms preprocess, 102.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 104.0ms\n",
      "Speed: 2.0ms preprocess, 104.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 110.0ms\n",
      "Speed: 2.0ms preprocess, 110.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 104.0ms\n",
      "Speed: 3.0ms preprocess, 104.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 100.0ms\n",
      "Speed: 1.9ms preprocess, 100.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 99.0ms\n",
      "Speed: 3.0ms preprocess, 99.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 101.0ms\n",
      "Speed: 3.0ms preprocess, 101.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 102.0ms\n",
      "Speed: 4.0ms preprocess, 102.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 105.0ms\n",
      "Speed: 3.0ms preprocess, 105.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 107.0ms\n",
      "Speed: 2.0ms preprocess, 107.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 99.0ms\n",
      "Speed: 2.0ms preprocess, 99.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 99.0ms\n",
      "Speed: 3.0ms preprocess, 99.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 107.0ms\n",
      "Speed: 4.0ms preprocess, 107.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 99.0ms\n",
      "Speed: 3.0ms preprocess, 99.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 100.1ms\n",
      "Speed: 3.0ms preprocess, 100.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 105.0ms\n",
      "Speed: 3.0ms preprocess, 105.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 102.1ms\n",
      "Speed: 2.0ms preprocess, 102.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 101.1ms\n",
      "Speed: 3.0ms preprocess, 101.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 102.0ms\n",
      "Speed: 3.0ms preprocess, 102.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 102.0ms\n",
      "Speed: 3.0ms preprocess, 102.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 104.0ms\n",
      "Speed: 3.0ms preprocess, 104.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 106.0ms\n",
      "Speed: 3.0ms preprocess, 106.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 99.0ms\n",
      "Speed: 3.0ms preprocess, 99.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 109.0ms\n",
      "Speed: 2.0ms preprocess, 109.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 103.0ms\n",
      "Speed: 2.0ms preprocess, 103.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 103.0ms\n",
      "Speed: 3.0ms preprocess, 103.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 107.2ms\n",
      "Speed: 2.0ms preprocess, 107.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 101.0ms\n",
      "Speed: 3.0ms preprocess, 101.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 107.0ms\n",
      "Speed: 3.0ms preprocess, 107.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 104.1ms\n",
      "Speed: 2.0ms preprocess, 104.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 102.0ms\n",
      "Speed: 3.0ms preprocess, 102.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 103.9ms\n",
      "Speed: 3.0ms preprocess, 103.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 103.0ms\n",
      "Speed: 3.0ms preprocess, 103.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 99.0ms\n",
      "Speed: 3.0ms preprocess, 99.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 104.0ms\n",
      "Speed: 3.0ms preprocess, 104.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 99.9ms\n",
      "Speed: 2.1ms preprocess, 99.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 105.1ms\n",
      "Speed: 4.0ms preprocess, 105.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 102.0ms\n",
      "Speed: 3.0ms preprocess, 102.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 96.0ms\n",
      "Speed: 3.0ms preprocess, 96.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 105.0ms\n",
      "Speed: 3.0ms preprocess, 105.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 106.1ms\n",
      "Speed: 3.0ms preprocess, 106.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 111.1ms\n",
      "Speed: 3.0ms preprocess, 111.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 109.0ms\n",
      "Speed: 2.0ms preprocess, 109.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 103.0ms\n",
      "Speed: 3.0ms preprocess, 103.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 102.0ms\n",
      "Speed: 4.0ms preprocess, 102.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 101.1ms\n",
      "Speed: 3.0ms preprocess, 101.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 104.0ms\n",
      "Speed: 2.0ms preprocess, 104.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 101.0ms\n",
      "Speed: 3.0ms preprocess, 101.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 104.0ms\n",
      "Speed: 2.0ms preprocess, 104.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 101.9ms\n",
      "Speed: 3.1ms preprocess, 101.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 101.1ms\n",
      "Speed: 3.0ms preprocess, 101.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 102.0ms\n",
      "Speed: 3.0ms preprocess, 102.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 100.0ms\n",
      "Speed: 5.0ms preprocess, 100.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 106.1ms\n",
      "Speed: 2.0ms preprocess, 106.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 100.0ms\n",
      "Speed: 2.0ms preprocess, 100.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 103.0ms\n",
      "Speed: 3.0ms preprocess, 103.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 102.0ms\n",
      "Speed: 3.0ms preprocess, 102.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 103.0ms\n",
      "Speed: 3.0ms preprocess, 103.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 103.0ms\n",
      "Speed: 3.0ms preprocess, 103.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 102.0ms\n",
      "Speed: 3.0ms preprocess, 102.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 105.0ms\n",
      "Speed: 2.0ms preprocess, 105.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 101.0ms\n",
      "Speed: 3.0ms preprocess, 101.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 103.0ms\n",
      "Speed: 2.0ms preprocess, 103.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 101.0ms\n",
      "Speed: 4.0ms preprocess, 101.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 135.1ms\n",
      "Speed: 4.0ms preprocess, 135.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 100.0ms\n",
      "Speed: 3.0ms preprocess, 100.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 108.1ms\n",
      "Speed: 4.9ms preprocess, 108.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 105.0ms\n",
      "Speed: 2.0ms preprocess, 105.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 101.1ms\n",
      "Speed: 3.0ms preprocess, 101.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 104.0ms\n",
      "Speed: 4.0ms preprocess, 104.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 103.0ms\n",
      "Speed: 3.0ms preprocess, 103.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 106.0ms\n",
      "Speed: 2.0ms preprocess, 106.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 103.0ms\n",
      "Speed: 3.0ms preprocess, 103.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 105.0ms\n",
      "Speed: 4.0ms preprocess, 105.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 103.0ms\n",
      "Speed: 3.0ms preprocess, 103.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 105.0ms\n",
      "Speed: 3.0ms preprocess, 105.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 105.0ms\n",
      "Speed: 3.0ms preprocess, 105.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 103.0ms\n",
      "Speed: 3.0ms preprocess, 103.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 106.0ms\n",
      "Speed: 3.0ms preprocess, 106.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 104.0ms\n",
      "Speed: 3.0ms preprocess, 104.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 101.0ms\n",
      "Speed: 2.0ms preprocess, 101.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 97.0ms\n",
      "Speed: 4.0ms preprocess, 97.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 104.0ms\n",
      "Speed: 4.0ms preprocess, 104.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 105.0ms\n",
      "Speed: 3.0ms preprocess, 105.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 105.0ms\n",
      "Speed: 4.0ms preprocess, 105.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 103.0ms\n",
      "Speed: 4.0ms preprocess, 103.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 102.0ms\n",
      "Speed: 4.0ms preprocess, 102.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 102.0ms\n",
      "Speed: 2.0ms preprocess, 102.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 102.0ms\n",
      "Speed: 2.0ms preprocess, 102.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 102.0ms\n",
      "Speed: 2.0ms preprocess, 102.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 105.0ms\n",
      "Speed: 3.0ms preprocess, 105.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 106.0ms\n",
      "Speed: 3.0ms preprocess, 106.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 103.0ms\n",
      "Speed: 3.0ms preprocess, 103.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 104.0ms\n",
      "Speed: 3.0ms preprocess, 104.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 106.0ms\n",
      "Speed: 4.1ms preprocess, 106.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 103.0ms\n",
      "Speed: 3.0ms preprocess, 103.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 107.0ms\n",
      "Speed: 3.0ms preprocess, 107.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 101.0ms\n",
      "Speed: 4.0ms preprocess, 101.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 102.0ms\n",
      "Speed: 3.0ms preprocess, 102.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 100.1ms\n",
      "Speed: 2.0ms preprocess, 100.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 103.0ms\n",
      "Speed: 5.0ms preprocess, 103.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 106.0ms\n",
      "Speed: 4.0ms preprocess, 106.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 101.1ms\n",
      "Speed: 3.0ms preprocess, 101.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 98.0ms\n",
      "Speed: 3.0ms preprocess, 98.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 106.0ms\n",
      "Speed: 3.0ms preprocess, 106.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 106.0ms\n",
      "Speed: 2.0ms preprocess, 106.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 106.1ms\n",
      "Speed: 3.0ms preprocess, 106.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 98.0ms\n",
      "Speed: 3.0ms preprocess, 98.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 99.0ms\n",
      "Speed: 4.0ms preprocess, 99.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 108.0ms\n",
      "Speed: 3.0ms preprocess, 108.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 124.0ms\n",
      "Speed: 4.0ms preprocess, 124.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 99.0ms\n",
      "Speed: 4.0ms preprocess, 99.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 101.0ms\n",
      "Speed: 3.0ms preprocess, 101.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 101.0ms\n",
      "Speed: 3.0ms preprocess, 101.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 105.0ms\n",
      "Speed: 2.0ms preprocess, 105.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 98.0ms\n",
      "Speed: 3.0ms preprocess, 98.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 106.1ms\n",
      "Speed: 2.0ms preprocess, 106.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 103.0ms\n",
      "Speed: 3.0ms preprocess, 103.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 101.0ms\n",
      "Speed: 4.1ms preprocess, 101.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 103.9ms\n",
      "Speed: 4.0ms preprocess, 103.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 100.1ms\n",
      "Speed: 4.0ms preprocess, 100.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 102.0ms\n",
      "Speed: 3.0ms preprocess, 102.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 100.0ms\n",
      "Speed: 2.1ms preprocess, 100.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 103.0ms\n",
      "Speed: 3.0ms preprocess, 103.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 104.0ms\n",
      "Speed: 3.0ms preprocess, 104.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 105.0ms\n",
      "Speed: 3.0ms preprocess, 105.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 99.0ms\n",
      "Speed: 4.0ms preprocess, 99.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 104.0ms\n",
      "Speed: 2.0ms preprocess, 104.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 108.0ms\n",
      "Speed: 2.0ms preprocess, 108.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 101.0ms\n",
      "Speed: 3.0ms preprocess, 101.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 104.0ms\n",
      "Speed: 2.0ms preprocess, 104.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 97.1ms\n",
      "Speed: 3.0ms preprocess, 97.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 141.0ms\n",
      "Speed: 3.0ms preprocess, 141.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 102.0ms\n",
      "Speed: 3.0ms preprocess, 102.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 101.0ms\n",
      "Speed: 4.0ms preprocess, 101.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 105.0ms\n",
      "Speed: 3.0ms preprocess, 105.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 105.0ms\n",
      "Speed: 3.0ms preprocess, 105.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 100.0ms\n",
      "Speed: 3.0ms preprocess, 100.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 104.0ms\n",
      "Speed: 3.0ms preprocess, 104.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 104.0ms\n",
      "Speed: 4.0ms preprocess, 104.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 109.0ms\n",
      "Speed: 3.0ms preprocess, 109.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 116.7ms\n",
      "Speed: 3.0ms preprocess, 116.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 123.0ms\n",
      "Speed: 2.0ms preprocess, 123.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 131.0ms\n",
      "Speed: 3.0ms preprocess, 131.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 135.0ms\n",
      "Speed: 3.0ms preprocess, 135.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 127.0ms\n",
      "Speed: 4.0ms preprocess, 127.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 128.0ms\n",
      "Speed: 3.0ms preprocess, 128.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 118.0ms\n",
      "Speed: 3.1ms preprocess, 118.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 122.0ms\n",
      "Speed: 4.0ms preprocess, 122.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 121.0ms\n",
      "Speed: 4.0ms preprocess, 121.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 127.0ms\n",
      "Speed: 4.0ms preprocess, 127.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 127.0ms\n",
      "Speed: 3.0ms preprocess, 127.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 121.0ms\n",
      "Speed: 3.0ms preprocess, 121.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 128.0ms\n",
      "Speed: 2.0ms preprocess, 128.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 124.0ms\n",
      "Speed: 3.0ms preprocess, 124.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 123.0ms\n",
      "Speed: 3.0ms preprocess, 123.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 122.0ms\n",
      "Speed: 2.0ms preprocess, 122.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 123.0ms\n",
      "Speed: 3.0ms preprocess, 123.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 120.0ms\n",
      "Speed: 3.1ms preprocess, 120.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 120.0ms\n",
      "Speed: 3.0ms preprocess, 120.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 121.0ms\n",
      "Speed: 3.0ms preprocess, 121.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 128.0ms\n",
      "Speed: 4.0ms preprocess, 128.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 126.0ms\n",
      "Speed: 2.0ms preprocess, 126.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 126.0ms\n",
      "Speed: 3.0ms preprocess, 126.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 126.0ms\n",
      "Speed: 4.0ms preprocess, 126.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 124.0ms\n",
      "Speed: 3.0ms preprocess, 124.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 125.1ms\n",
      "Speed: 3.0ms preprocess, 125.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 115.0ms\n",
      "Speed: 3.0ms preprocess, 115.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 112.0ms\n",
      "Speed: 3.0ms preprocess, 112.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 121.0ms\n",
      "Speed: 3.1ms preprocess, 121.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 114.0ms\n",
      "Speed: 3.0ms preprocess, 114.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 119.0ms\n",
      "Speed: 4.0ms preprocess, 119.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 124.0ms\n",
      "Speed: 4.0ms preprocess, 124.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 126.0ms\n",
      "Speed: 4.0ms preprocess, 126.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 125.0ms\n",
      "Speed: 3.0ms preprocess, 125.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 119.9ms\n",
      "Speed: 3.1ms preprocess, 119.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 118.0ms\n",
      "Speed: 4.0ms preprocess, 118.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 126.0ms\n",
      "Speed: 3.0ms preprocess, 126.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 123.0ms\n",
      "Speed: 3.0ms preprocess, 123.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 122.0ms\n",
      "Speed: 4.0ms preprocess, 122.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 126.0ms\n",
      "Speed: 4.0ms preprocess, 126.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 122.0ms\n",
      "Speed: 4.0ms preprocess, 122.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 121.0ms\n",
      "Speed: 3.0ms preprocess, 121.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 125.0ms\n",
      "Speed: 3.0ms preprocess, 125.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 169.1ms\n",
      "Speed: 3.0ms preprocess, 169.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 124.0ms\n",
      "Speed: 4.0ms preprocess, 124.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 117.0ms\n",
      "Speed: 3.0ms preprocess, 117.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 124.0ms\n",
      "Speed: 4.0ms preprocess, 124.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 128.0ms\n",
      "Speed: 4.0ms preprocess, 128.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 119.0ms\n",
      "Speed: 3.0ms preprocess, 119.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 126.0ms\n",
      "Speed: 3.0ms preprocess, 126.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 121.0ms\n",
      "Speed: 3.0ms preprocess, 121.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 129.0ms\n",
      "Speed: 2.0ms preprocess, 129.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 217.0ms\n",
      "Speed: 4.0ms preprocess, 217.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 125.0ms\n",
      "Speed: 5.0ms preprocess, 125.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 125.0ms\n",
      "Speed: 3.0ms preprocess, 125.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 117.9ms\n",
      "Speed: 3.1ms preprocess, 117.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 126.0ms\n",
      "Speed: 3.0ms preprocess, 126.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 125.0ms\n",
      "Speed: 3.0ms preprocess, 125.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 122.0ms\n",
      "Speed: 3.0ms preprocess, 122.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 114.0ms\n",
      "Speed: 3.0ms preprocess, 114.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 118.0ms\n",
      "Speed: 3.0ms preprocess, 118.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 122.0ms\n",
      "Speed: 3.0ms preprocess, 122.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 119.0ms\n",
      "Speed: 3.0ms preprocess, 119.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 122.0ms\n",
      "Speed: 3.0ms preprocess, 122.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 120.0ms\n",
      "Speed: 3.0ms preprocess, 120.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 121.0ms\n",
      "Speed: 4.0ms preprocess, 121.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 116.0ms\n",
      "Speed: 4.0ms preprocess, 116.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 124.0ms\n",
      "Speed: 3.0ms preprocess, 124.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 122.0ms\n",
      "Speed: 4.0ms preprocess, 122.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 123.1ms\n",
      "Speed: 2.0ms preprocess, 123.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 117.0ms\n",
      "Speed: 4.0ms preprocess, 117.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 123.0ms\n",
      "Speed: 3.0ms preprocess, 123.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 115.0ms\n",
      "Speed: 3.0ms preprocess, 115.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 116.1ms\n",
      "Speed: 4.0ms preprocess, 116.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 117.2ms\n",
      "Speed: 3.0ms preprocess, 117.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 124.0ms\n",
      "Speed: 3.0ms preprocess, 124.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 120.9ms\n",
      "Speed: 3.0ms preprocess, 120.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 122.0ms\n",
      "Speed: 3.0ms preprocess, 122.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 117.0ms\n",
      "Speed: 3.0ms preprocess, 117.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 123.0ms\n",
      "Speed: 3.0ms preprocess, 123.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 120.0ms\n",
      "Speed: 3.0ms preprocess, 120.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 121.0ms\n",
      "Speed: 4.0ms preprocess, 121.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 111.9ms\n",
      "Speed: 3.0ms preprocess, 111.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 122.0ms\n",
      "Speed: 3.0ms preprocess, 122.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 123.0ms\n",
      "Speed: 4.0ms preprocess, 123.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 122.0ms\n",
      "Speed: 3.0ms preprocess, 122.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 119.0ms\n",
      "Speed: 3.0ms preprocess, 119.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 123.0ms\n",
      "Speed: 3.0ms preprocess, 123.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 120.9ms\n",
      "Speed: 4.0ms preprocess, 120.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 109.0ms\n",
      "Speed: 3.1ms preprocess, 109.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 120.0ms\n",
      "Speed: 2.0ms preprocess, 120.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 118.0ms\n",
      "Speed: 4.0ms preprocess, 118.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 139.0ms\n",
      "Speed: 4.0ms preprocess, 139.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 119.9ms\n",
      "Speed: 3.0ms preprocess, 119.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 125.0ms\n",
      "Speed: 3.0ms preprocess, 125.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 122.0ms\n",
      "Speed: 3.0ms preprocess, 122.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 114.0ms\n",
      "Speed: 3.0ms preprocess, 114.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 122.0ms\n",
      "Speed: 3.0ms preprocess, 122.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 123.0ms\n",
      "Speed: 4.0ms preprocess, 123.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 115.0ms\n",
      "Speed: 3.0ms preprocess, 115.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 116.0ms\n",
      "Speed: 3.0ms preprocess, 116.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 121.0ms\n",
      "Speed: 3.0ms preprocess, 121.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 121.0ms\n",
      "Speed: 3.0ms preprocess, 121.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 127.0ms\n",
      "Speed: 3.0ms preprocess, 127.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 121.0ms\n",
      "Speed: 4.0ms preprocess, 121.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 122.0ms\n",
      "Speed: 4.0ms preprocess, 122.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 120.0ms\n",
      "Speed: 2.0ms preprocess, 120.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 122.0ms\n",
      "Speed: 3.0ms preprocess, 122.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 121.0ms\n",
      "Speed: 3.0ms preprocess, 121.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 121.0ms\n",
      "Speed: 5.0ms preprocess, 121.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 119.0ms\n",
      "Speed: 4.0ms preprocess, 119.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 122.0ms\n",
      "Speed: 3.0ms preprocess, 122.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 122.0ms\n",
      "Speed: 5.0ms preprocess, 122.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 126.0ms\n",
      "Speed: 3.0ms preprocess, 126.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 112.0ms\n",
      "Speed: 3.0ms preprocess, 112.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 123.0ms\n",
      "Speed: 3.0ms preprocess, 123.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 123.0ms\n",
      "Speed: 3.0ms preprocess, 123.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 129.0ms\n",
      "Speed: 2.0ms preprocess, 129.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 121.0ms\n",
      "Speed: 4.0ms preprocess, 121.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 120.0ms\n",
      "Speed: 5.0ms preprocess, 120.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 120.0ms\n",
      "Speed: 4.0ms preprocess, 120.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 121.0ms\n",
      "Speed: 3.0ms preprocess, 121.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 118.0ms\n",
      "Speed: 3.0ms preprocess, 118.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 122.0ms\n",
      "Speed: 4.0ms preprocess, 122.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 121.0ms\n",
      "Speed: 3.0ms preprocess, 121.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 123.0ms\n",
      "Speed: 4.0ms preprocess, 123.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 123.0ms\n",
      "Speed: 3.0ms preprocess, 123.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 121.0ms\n",
      "Speed: 3.0ms preprocess, 121.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 120.0ms\n",
      "Speed: 3.0ms preprocess, 120.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 122.0ms\n",
      "Speed: 3.0ms preprocess, 122.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 133.0ms\n",
      "Speed: 2.0ms preprocess, 133.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 119.0ms\n",
      "Speed: 3.0ms preprocess, 119.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 120.0ms\n",
      "Speed: 5.0ms preprocess, 120.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 123.0ms\n",
      "Speed: 3.0ms preprocess, 123.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 113.0ms\n",
      "Speed: 4.0ms preprocess, 113.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 121.0ms\n",
      "Speed: 5.0ms preprocess, 121.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 121.0ms\n",
      "Speed: 2.0ms preprocess, 121.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 178.0ms\n",
      "Speed: 3.0ms preprocess, 178.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 118.0ms\n",
      "Speed: 4.0ms preprocess, 118.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 135.0ms\n",
      "Speed: 4.0ms preprocess, 135.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 126.0ms\n",
      "Speed: 3.0ms preprocess, 126.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 120.0ms\n",
      "Speed: 4.0ms preprocess, 120.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 126.0ms\n",
      "Speed: 3.0ms preprocess, 126.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 123.0ms\n",
      "Speed: 3.0ms preprocess, 123.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 120.0ms\n",
      "Speed: 3.0ms preprocess, 120.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 125.0ms\n",
      "Speed: 4.0ms preprocess, 125.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 114.0ms\n",
      "Speed: 5.0ms preprocess, 114.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 121.0ms\n",
      "Speed: 3.0ms preprocess, 121.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 114.0ms\n",
      "Speed: 3.0ms preprocess, 114.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 116.0ms\n",
      "Speed: 4.0ms preprocess, 116.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 122.0ms\n",
      "Speed: 2.0ms preprocess, 122.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 121.0ms\n",
      "Speed: 4.0ms preprocess, 121.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 123.0ms\n",
      "Speed: 3.0ms preprocess, 123.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 121.0ms\n",
      "Speed: 3.0ms preprocess, 121.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 111.0ms\n",
      "Speed: 3.0ms preprocess, 111.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 119.9ms\n",
      "Speed: 3.1ms preprocess, 119.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 117.9ms\n",
      "Speed: 3.0ms preprocess, 117.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 115.0ms\n",
      "Speed: 3.0ms preprocess, 115.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 130.0ms\n",
      "Speed: 3.0ms preprocess, 130.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 120.0ms\n",
      "Speed: 3.0ms preprocess, 120.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 121.0ms\n",
      "Speed: 3.0ms preprocess, 121.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 121.0ms\n",
      "Speed: 3.0ms preprocess, 121.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 122.1ms\n",
      "Speed: 3.0ms preprocess, 122.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 124.0ms\n",
      "Speed: 3.0ms preprocess, 124.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 118.0ms\n",
      "Speed: 3.0ms preprocess, 118.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 122.0ms\n",
      "Speed: 3.0ms preprocess, 122.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 120.0ms\n",
      "Speed: 3.1ms preprocess, 120.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 117.0ms\n",
      "Speed: 3.0ms preprocess, 117.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 117.0ms\n",
      "Speed: 4.0ms preprocess, 117.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 114.0ms\n",
      "Speed: 3.0ms preprocess, 114.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 115.0ms\n",
      "Speed: 3.0ms preprocess, 115.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 114.0ms\n",
      "Speed: 3.0ms preprocess, 114.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 114.0ms\n",
      "Speed: 4.0ms preprocess, 114.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 121.0ms\n",
      "Speed: 2.9ms preprocess, 121.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 105.0ms\n",
      "Speed: 3.0ms preprocess, 105.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 111.9ms\n",
      "Speed: 4.1ms preprocess, 111.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "# Open the video file\n",
    "video_path = \"videos\\pexels_soccer_shoot.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # Run YOLOv8 inference on the frame\n",
    "        results = model(frame)\n",
    "\n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # Display the annotated frame\n",
    "        cv2.imshow(\"YOLOv8 Inference\", annotated_frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
